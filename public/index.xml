<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Connecting the dots</title>
    <link>https://fanggong.pub/</link>
    <description>Recent content on Connecting the dots</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ch</language>
    <lastBuildDate>Tue, 22 Jun 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://fanggong.pub/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>scikit-learn的特征选择相关接口整理</title>
      <link>https://fanggong.pub/posts/20210622_sklearn_feature_selection_api/</link>
      <pubDate>Tue, 22 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://fanggong.pub/posts/20210622_sklearn_feature_selection_api/</guid>
      <description>sklearn.feature_selection.GenericUnivariateSelectsklearn.feature_selection.SelectFromModelsklearn.feature_selection.SequentialFeatureSelectorsklearn.feature_selection.VarianceThresholdsklearn.feature_selection.RFE不要重复造轮子。
sklearn.feature_selection.GenericUnivariateSelect对每个特征与目标变量求score_func的值，根据结果按照mode选择满足param条件的特征。
score_func应该满足接收n个特征变量和1个目标变量，返回一对长度为n的数组分别表示scores和pvalues。sklearn中提供了5个可能高频率使用的score_func：
chi2：卡方统计量，适用于多个二分类特征（或是one-hot编码后的多水平分类特征）和分类目标变量；f_classif：方差分析的F统计量，适用于连续特征和分类目标变量；f_regression：单变量线性回归的F统计量，适用于连续特征和连续目标变量；mutual_info_classif：互信息，适用于分类目标变量；mutual_info_regression：互信息，适用于连续目标变量。此外提供了5种选择mode：
percentile：根据scores选择得分最高的前一定比例的特征；k_best：根据scores选择得分最高的前k个特征；fpr：根据pvalues选择低于某值的特征；fdr：False discovery ratefwe：Family-wise error rate自定义score_func示例如下（并没有什么实际意义）：
def my_score_func(X, y):return (X.sum(axis=0), X.mean(axis=0))from sklearn.datasets import load_breast_cancerfrom sklearn.feature_selection import GenericUnivariateSelect, chi2X, y = load_breast_cancer(return_X_y=True)print(X.shape)## (569, 30)transformer = GenericUnivariateSelect(my_score_func, mode=&amp;#39;k_best&amp;#39;, param=10)X_new = transformer.fit_transform(X, y)print(X_new.shape)## (569, 10)sklearn.</description>
    </item>
    
    <item>
      <title>htmlwidgets包的使用</title>
      <link>https://fanggong.pub/posts/20210617_create_your_own_widgets/</link>
      <pubDate>Thu, 17 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://fanggong.pub/posts/20210617_create_your_own_widgets/</guid>
      <description>项目结构搭建相关依赖的配置R与JS的绑定对htmlwidgets的size进行调整完善package的其它信息写在最后htmlwidgets包为R提供了一个封装JS代码的框架。通过JS生成的htmlwidgets可以直接使用在Rmarkdown和Shiny中。
本文记录了一个简单的htmlwidgets的开发流程，封装了一个JS库flipdown.js，可以在Rmarkdown或Shiny中创建一个倒计时时钟。
封装的JS代码和R函数以一个包的形式存在，该包已经上传到CRAN，可以通过以下代码安装：
install.packages(&amp;quot;flipdownWidgets&amp;quot;)或是通过Github安装：
# install.packages(&amp;quot;devtools&amp;quot;)devtools::install_github(&amp;quot;fanggong/flipdownWidgets&amp;quot;)项目结构搭建首先创建一个R package项目
devtools::create(&amp;quot;flipdownWidgets&amp;quot;)初始化开发环境并安装必要的包
renv::init()renv::install(&amp;quot;htmlwidgets&amp;quot;)renv::install(&amp;quot;devtools&amp;quot;)创建widget的脚手架
htmlwidgets::scaffoldWidget(&amp;quot;flipdownWidgets&amp;quot;)生成函数说明文件
devtools::document()安装包
devtools::install()测试
flipdownWidgets::flipdownWidgets(&amp;quot;Hello World!&amp;quot;)上面的基础结构实现了一个简单的htmlwidgets：向R函数flipdownWidgets()传递参数Hello World!，该参数会被传给对应的JS函数，JS函数的功能是将参数输出到网页上。
相关依赖的配置接下来要进行对相关JS库的依赖配置。
找到对应JS库的.js和.css文件，复制到项目中的/inst/htmlwidgets路径下。在这里，我们需要复制的文件为flipdown.js和flipdown.css。之后修改配置文件/inst/htmlwidgets/flipdownWidgets.yaml指定依赖。
dependencies:- name: flipdownversion: 0.3.2src: &amp;quot;htmlwidgets/lib/flipdown&amp;quot;script: flipdown.jsstylesheet: flipdown.cssR与JS的绑定一个最简单的htmlwidgets应该至少包含了以下四个函数：
R捆绑函数：该函数是一个R函数，它接收数据和其它关于htmlwidgets的可选项，生成一个htmlwidgets对象。在这里，该函数的基本结构通过前面的scaffoldWidget(&#34;flipdownWidgets&#34;)自动生成在/R/flipdownWidgets.R文件中；JS捆绑函数：该函数是一个JS工厂函数，它接收将要容纳这个htmlwidgets的HTML元素以及HTML元素的宽度和高度，然后通过其中的renderValue()方法创建htmlwidgets。renderValue()除了JS捆绑函数的参数外，还会接收R捆绑函数中的参数（即数据和关于htmlwidgets的可选项）。JS捆绑函数的基本结构同样会通过scaffoldWidget(&#34;flipdownWidgets&#34;)自动生成在/inst/htmlwidgets/flipdownWidgets.js文件中；flipdownWidgetsOutput函数：该函数供Shiny使用，自动生成，一般不需要做修改；renderFlipdownWidgets函数：该函数同样供Shiny使用，自动生成，一般不做修改。这里我们需要做的其实就是以下两点：
确定R捆绑函数对应的输入参数，将这些参数在R捆绑函数中经过合适的转换之后打包为一个列表传入R捆绑函数内的htmlwidgets::createWidget()函数；
编写JS捆绑函数中的renderValue()方法，使用R捆绑函数的参数在HTML元素中生成一个htmlwidgets。对htmlwidgets的size进行调整在JS捆绑函数中除了renderValue()方法外，还提供了一个resize()方法。通过resize()方法即可实现根据显示位置的大小调整htmlwidgets的size。</description>
    </item>
    
    <item>
      <title>参数正则化</title>
      <link>https://fanggong.pub/posts/20210611_regularization/</link>
      <pubDate>Fri, 11 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://fanggong.pub/posts/20210611_regularization/</guid>
      <description>线性回归的正则化关于L2参数正则化的理论分析关于L1参数正则化的理论分析L2正则化和L1正则化的比较以下内容主要参考自scikit-learn文档和Deep Learning一书。
线性回归的正则化对于参数正则化最早的接触来自于线性回归。
Lasso回归使用L1范数进行参数正则化，即回归的目标函数为：\[{1 \over 2N }\left \| X\omega-y \right \|_2^2 + \alpha \left \| \omega \right \|_1\]
岭回归使用L2范数进行参数正则化，即回归的目标函数为：\[\left \| X\omega-y \right \|_2^2 + \alpha \left \| \omega \right \|_2^2\]
Elasti-Net回归的正则项结合了L1范数和L2范数，其目标函数为：\[{1 \over 2N }\left \| X\omega-y \right \|_2^2 + \alpha \rho \left \| \omega \right \|_1 + {\alpha (1-\rho) \over 2} \left \| \omega \right \|_2^2\]</description>
    </item>
    
    <item>
      <title>Shiny：对Reactive对象进行修改</title>
      <link>https://fanggong.pub/posts/20210606_shiny_update_reactive_object/</link>
      <pubDate>Sun, 06 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://fanggong.pub/posts/20210606_shiny_update_reactive_object/</guid>
      <description>问题背景实现方式问题背景需要根据初始输入生成一个对象，该对象以某种形式展示。同时，针对其它的输入（多个输入源的多次输入），对该对象进行多次修改，每次修改后，该对象的展示结果对应发生改变。当初始输入改变时，重新初始化该对象。
实现方式很显然应该使用reactive对象，但是试了很多种方法，发现通过reactive()生成的reactive对象是无法进行任何修改的，即上方的“针对其它的输入对对象进行多次修改”无法实现。最后发现貌似只有通过reactiveValues()才能实现该功能。
View Code
</description>
    </item>
    
    <item>
      <title>对本主题的样式的测试</title>
      <link>https://fanggong.pub/posts/always_today/</link>
      <pubDate>Wed, 02 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://fanggong.pub/posts/always_today/</guid>
      <description>任何做个人博客的人应该都过不了对样式无穷无尽的修改这个坎吧…
这是一级标题这是二级标题这是三级标题页内跳转点这里跳到样式——表格点着里跳到样式——iframe无序列表御田的决心！白胡子的试炼!白胡子的弟弟！御田的大冒险兵刃相接！罗杰与白胡子！有序列表新的同盟！？凯多军大集结决战迫近！草帽一伙进入战斗状态大新闻！七武海袭击事件嵌套列表元气森林0糖0脂肪0卡路里代码块height &amp;lt;- rnorm(100, 170, 8)weight &amp;lt;- rnorm(100, 70, 12)t.test(height, weight)## ## Welch Two Sample t-test## ## data: height and weight## t = 70.456, df = 184.02, p-value &amp;lt; 2.</description>
    </item>
    
    <item>
      <title>adaboost原理</title>
      <link>https://fanggong.pub/posts/20210530_adaboost/</link>
      <pubDate>Sun, 30 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://fanggong.pub/posts/20210530_adaboost/</guid>
      <description>AdaBoost算法原理关于样本权重的求解回归问题下的AdaBoostAdaBoost的正则化关于AdaBoost的几点思考AdaBoost算法原理AdaBoost的基本思想是通过不断修改训练样本的权重来训练新的基学习器，最后将所有基学习器进行加权求和从而得到一个集成模型。即，AdaBoost可以表示为基学习器的加法模型：\[\hat y_i = \sum_{k=1}^K \alpha_k G_k(x_i)\]其中\(G_k\)为第\(k\)个基学习器，\(\alpha_k\)为其系数。
以二分类模型为例，将目标变量以±1的形式表示，损失函数定义为指数损失函数，即：\[l(y, \hat y) = e^{-y \hat y}\]
设第t个基分类器为\(G_t(x)\)，那么有：\[\hat y^{(t)}_i = \hat y^{(t-1)}_i + \alpha_t G_t(x_i)\]
其目标函数可以表示为：\[\begin{aligned}obj^{(t)} &amp;amp; = \sum_{i=1}^N e^{-y_i \hat y^{(t-1)}_i -y_i\alpha_tG_t(x_i)} \\&amp;amp; = \sum_{i=1}^N \omega_i^{(t)} e^{-y_i \alpha_tG_t(x_i)} \end{aligned}\]其中\(\omega_i^{(t)} = e^{-y_i \hat y^{(t-1)}_i}\)是一个常数可以理解为前t-1个基分类器的预测值带入损失函数得到的值。
观察上面的目标函数可以发现，对于任意的大于0的\(\alpha_t\)，当\(y_i = G_t(x_i)\)时，\(\omega_i^{(t)}\)会被乘上一个小于1的值（即\(e^{-\alpha_t}\)），当\(y_i \ne G_t(x_i)\)时，\(\omega_i^{(t)}\)会被乘上一个大于1的值（即\(e^{\alpha_t}\)）。</description>
    </item>
    
    <item>
      <title>R语言项目环境管理</title>
      <link>https://fanggong.pub/posts/20210521_renv/</link>
      <pubDate>Fri, 21 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://fanggong.pub/posts/20210521_renv/</guid>
      <description>环境初始化对环境管理renv的全局缓存移除环境相关包：renv
第一次知道这个包是在很早的时候，但是并没有什么使用的动力，毕竟我的电脑很久才会换一次，而公司的服务器，已经很久没有换过了…所有并没有频繁在新环境中运行代码的需求。直到有一天，当我想把docker和R一起使用以解决R的无法并行的问题时，终于体会到了renv的真香。
环境初始化在一个新的项目中使用renv::init()对环境进行初始化，该操作会生成一个名为renv的文件夹和名为renv.lock的文件。
renv下保存了在环境中已安装的包的文件（准确的说是已安装包的符号链接文件），而renv.lock指定了该项目对renv下的包的相关依赖。
对环境管理使用renv::restore()和renv::snapshot()对环境进行管理。
renv::restore()根据renv.lock文件安装环境中缺少的包到renv文件夹下（这个描述不是很准确，包的安装位置实际是global package cache中，renv文件夹下存在的是对应包的符号链接文件）。
renv::snapshot()根据当前环境下的项目情况将依赖写入renv.lock文件中。
这里的逻辑有点绕但是很合理：如果某个包已经安装在了renv中但是在实际项目中没有被使用，那么renv::snapshot()是不会将该包写入renv.lock文件中的。这也就是说，我们可以没有什么心理压力地安装各种包了，它只会污染你的开发环境而不会污染生产环境。
renv的全局缓存在使用了renv的项目中安装新的包时，包并不会被安装在我们安装R时指定的包存储路径，而是安装在了renv的全局包缓存中（global package cache）。两者之间最大的区别我认为在于后者中可以存在同一个包的不同版本。
当使用renv::restore()时，如果该包存在于global package cache中，那么在renv文件夹下会形成该包的符号链接；如果global package cache中不存在该包，那么会先将该包安装到global package cache中，然后形成符号链接。同时可以使用renv::isolate()将cache中的包复制到renv文件夹中从而切断对cache的依赖。
renv的global package cache路径为：
Mac：~/Library/Application Support/renvLinux：~/.local/share/renvWindows：%LOCALAPPDATA%/renv移除环境使用renv::deactivate()使renv无效，即项目回到使用全局环境的状态。该命令只会删除.Rprofile文件使得renv相关文件无效，而不会删除renv相关文件以防止需要重新启用renv。但对于我这种轻度强迫症来说，没有用的文件是一定不能留在项目里的，所以我选择手动删除项目中的所有renv相关文件。
</description>
    </item>
    
    <item>
      <title>xgboost原理</title>
      <link>https://fanggong.pub/posts/20210517_xgboost/</link>
      <pubDate>Mon, 17 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://fanggong.pub/posts/20210517_xgboost/</guid>
      <description>目标函数：损失函数 + 正则项决策树集成xgboost的损失函数xgboost的正则项xgboost的目标函数寻找最优结构的树几个比较纠结的问题参考文章：
Introduction to Boosted TreesXGBoost: A Scalable Tree Boosting System以下内容主要是对上面文章内容的整理以及一些个人理解。
目标函数：损失函数 + 正则项在机器学习模型中，目标函数一般由损失函数和正则项组成：\[obj(\theta) = L(\theta) + \Omega(\theta)\]
其中\(L(\theta)\)为损失函数，在回归模型中，我们常常定义为MSE，即：\[L(\theta) = \sum_i(y_i - \hat y_i)^2\]或是在逻辑回归模型中，我们定义为：\[L(\theta) = \sum_i \left[ y_i\ln(1 + e^{-\hat y_i}) + (1 - y_i)\ln(1 + e^{\hat y_i}) \right]\]（逻辑回归的损失函数非常直观：当\(y_i\)为1时，\(\hat y_i\)越大则\(L(\theta)\)越小；而当\(y_i\)为0时，\(\hat y_i\)越小则\(L(\theta)\)越小）</description>
    </item>
    
    <item>
      <title>差异显著性检验</title>
      <link>https://fanggong.pub/posts/20210513_difference_analysis/</link>
      <pubDate>Thu, 13 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://fanggong.pub/posts/20210513_difference_analysis/</guid>
      <description>单样本的差异显著性分析两样本的差异显著性分析多样本的差异显著性分析各检验方法的R语言实现下面记述的各种情况及适用的差异显著性检验的相关方法都是以样本之间相互独立为前提的。对于样本之间不相互独立的情况，应该针对具体情况使用特定的方法。
单样本的差异显著性分析连续变量的单样本对于连续变量的单样本，一般需要检验的是该样本是否取自于均值为\(\mu_0\)的总体，其采用的检验方法一般为t检验或z检验。根据Wikipedia，当样本量较小且样本来自于标准差未知的正态总体时，适用t检验；当样本量较大或总体方差已知时，由于中心极限定理，可以使用z检验。
（这个描述从第一次接触统计学开始就困扰着我，总体方差怎么会已知，都已知总体方差了总体均值为什么会未知）
无序离散变量的单样本对于无序离散变量的单样本，一般检验的是样本所在总体中某类别占比（即率）是否等于\(p_0\)。在大样本下，样本率是服从正态分布的，故可以直接使用z检验；在小样本下，可以看作对伯努利试验（属于该类别和不属于该类别）的成功率\(p\)是否等于\(p_0\)的检验，故可以使用精确二项检验(Exact Binomial Test)。
有序离散变量的单样本对于有序离散变量的单样本，个人认为需要根据实际目的选择检验方法。如果关注的是变量的整体的形态，可以根据变量服从的分布选择如精确泊松检验等，或是将有序离散变量当作连续变量，在近似服从正态分布的前提下使用t检验或z检验。如果关注的变量中类别的比例，那么可以直接将有序离散变量当作无序离散变量做对应的显著性检验。
两样本的差异显著性分析连续变量的两样本对于连续变量的两样本的差异显著性检验，可以分成下面三种情况：
样本均取自服从正态分布的总体且满足方差齐性，使用t检验样本均取自服从正态分布的总体但是不满足方差齐性，使用近似t检验样本并非均取自服从正态分布的总体，使用Wilcoxon秩和检验无序离散变量的两样本对于无序离散变量的两样本的差异显著性检验，需要将数据变换成列联表后进行显著性检验，检验方法可以分成以下两类：
变量的水平（类别数）等于2列联表中频数总和大于等于40且每个格子的期望频数均大于等于5时，使用Pearson卡方检验列联表中频数总和大于等于40且存在某个格子的期望频数大于等于1而小于5时，使用连续性校正卡方检验列联表中频数综合小于40或存在某个格子的期望频数小于1时，使用Fisher精确检验变量的水平大于280%以上的格子期望频数大于等于5且所有格子的期望频数均大于等于1时，使用Pearson卡方检验20%以上的格子期望频数小于5或存在某个格子的期望频数小于1时，使用Fisher精确检验有序离散变量的两样本对于有序离散变量的两样本的差异显著性检验，同样需要将数据变换成列联表后进行显著性检验，检验方法可以分成以下两类：
两组样本的样本量均大于50，使用Ridit分析存在某组样本的样本量小于等于50，使用Wilcoxon秩和检验多样本的差异显著性分析连续变量的多样本对于连续变量的两样本的差异显著性检验，可以分成下面两种情况：
样本均取自服从正态分布的总体且满足方差齐性，使用方差分析样本并非取自服从正态分布的总体或不满足方差齐性，使用K-W秩和检验无序离散变量的多样本对于无序离散变量的多样本的差异显著性检验，将数据变换成列联表后进行显著性检验，检验方法可以分成以下两类：
80%以上的格子期望频数大于等于5且所有格子的期望频数均大于等于1时，使用Pearson卡方检验20%以上的格子期望频数小于5或存在某个格子的期望频数小于1时，使用Fisher精确检验有序离散变量的多样本对于有序离散变量的多样本的差异显著性检验，将数据变换成列联表后进行显著性检验，检验方法可以分成以下两类：</description>
    </item>
    
    <item>
      <title>极大似然估计(MLE)和最大后验概率估计(MAP)</title>
      <link>https://fanggong.pub/posts/20210510_mle_and_map/</link>
      <pubDate>Mon, 10 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://fanggong.pub/posts/20210510_mle_and_map/</guid>
      <description>频率学派与贝叶斯学派极大似然估计(MLE)最大后验概率估计(MAP)频率学派与贝叶斯学派关于频率学派与贝叶斯学派的标准解释网上有很多，下面是个人的一些理解。
频率学派频率学派认为世界是确定的，也即某个事件发生的概率是确定的。在一次试验中无论该事件发生还是不发生都只是其发生概率\(p\)的一次体现而已。所以当进行多次重复试验时，事件发生的次数占总试验次数的比例就会逐渐接近这个事件的发生概率\(p\)。
在上述的前提下，如果想要知道这个\(p\)，那么只需要进行多次试验，然后解出\(p\)的最可能的取值即可。这就是从最初开始学习统计学时就接触到的极大似然估计(MLE)。很显然，在频率学派的方法下，当进行足够多的试验后即积累足够的数据量时我们可以得到一个很接近\(p\)的估计。
贝叶斯学派与频率学派不同，贝叶斯学派认为世界是不确定的，它是随着我们对世界的认知改变的（就感觉很主观，但是又主观得很有道理…）。因此，在贝叶斯学派下，事件发生的概率\(p\)并不是一个确定的数字，根据不同的认知（即先验假设）对\(p\)应该作出不一样的估计，即最大后验概率估计(MAP)。
随着试验次数的增加，我们的先验假设的作用被逐渐淡化，数据中体现的信息将会在估计中占据主导作用，因此当数据量足够大时，会发现两种估计方法会得到相同的结论。
极大似然估计(MLE)以丢硬币为例，丢硬币10次，其中正面朝上7次，反面朝上3次，使用极大似然估计求解正面朝上的概率\(p\)。
有似然函数：\[f(X, p) = P(X|p) = p^7(1-p)^3\]取对数：\[\ln f(X, p) = 7\ln p + 3\ln(1-p) \]求导得到：\[(\ln f(X, p))&amp;#39; = {7p + 3p - 7 \over p(p-1)} = {10p - 7 \over p^2-p}\]令上式等于0可以得到\(p\)等于0.7。即当丢一个硬币10次，其中正面朝上7次，反面朝上3次时，极大似然估计认为正面朝上的概率最可能是0.7。
我们知道一个均匀的硬币正面朝上的概率应该是0.5，所以当数据量较小时，极大似然估计的结果与我们的先验知识就产生了偏差（在数据量大的情况下并不会有这样的问题，因为如果丢一个硬币10000次，正面朝上7000次，反面朝上3000次，那么应该做的是好好查查这个硬币是不是真的是均匀的了）。
最大后验概率估计(MAP)在极大似然估计中我们寻找使得\(P(X|p)\)取到最大值的\(p\)，而在最大后验概率估计中，我们寻找的是使得\(P(X|p)P(p)\)取到最大值的\(p\)。
根据贝叶斯公式有：\[P(X|p)P(p) = P(p|X)P(X)\]这里的\(P(X)\)是一个已知的值（7次正面，3次反面），所以我们要求解的实际是使得\(P(p|X)\)（即后验概率，故称为最大后验概率估计）取到最大值的\(p\)。</description>
    </item>
    
    <item>
      <title>梯度提升树（GBDT）原理</title>
      <link>https://fanggong.pub/posts/20210507_gbdt/</link>
      <pubDate>Fri, 07 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://fanggong.pub/posts/20210507_gbdt/</guid>
      <description>GBDT算法原理回归问题下的GDBT二分类问题下的GBDT多分类问题下的GBDTGBDT算法原理GBDT可以表示为决策树的加法模型，即：\[\hat y_i = \sum_{k=1}^K f_k(x_i)\]其中\(f\)表示决策树，\(K\)为决策树的数量。
通过前向分步骤算法，第t步得到的决策树模型为\(f_t(x)\)，有：\[\hat y_i^{(t)} = \hat y_i^{(t-1)} + f_t(x_i)\]其目标函数为：\[obj^{(t)} = \sum_{i=1}^N l\left(y_i, \hat y_i^{(t-1)} + f_t(x_i) \right)\]将目标函数使用泰勒一阶展开，有：\[obj^{(t)} = \sum_{i=1}^N \left[ l(y_i, \hat y_i^{(t-1)}) + g_i f_t(x_i) \right]\]这里的\(g_i = \left[ {\partial\ l(y_i, \hat y_i) \over \partial \hat y_i} \right]_{\hat y_i = \hat y_i^{(t-1)}}\)，即损失函数关于\(\hat y_i\)求导后带入\(\hat y_i = \hat y_i^{(t-1)}\)。</description>
    </item>
    
    <item>
      <title>决策树的特征选择标准</title>
      <link>https://fanggong.pub/posts/20210428_concepts_about_decision_tree/</link>
      <pubDate>Wed, 28 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://fanggong.pub/posts/20210428_concepts_about_decision_tree/</guid>
      <description>信息熵(Entropy)条件熵(Conditional Entropy)信息增益(Information Gain, IG)信息增益比(Information Gain Ratio)基尼指数(Gini Index)信息熵(Entropy)设\(Y\)是取有限个值的离散随机变量，其概率分布为：\[P(Y = y_i) = p_i,\quad i = 1, 2, 3, ..., n\]
则随机变量\(Y\)的熵的定义为：\[H(Y) = -\sum_{i=1}^n p_i\log_bp_i\]根据对数的底\(b\)的不同，熵的单位不同。当\(b\)为2时，单位为比特(bit)，当\(b\)为e时，单位为纳特(nat)。
熵被认为是不确定性的度量。很显然当系统内只有一个事件且该事件必定发生时，熵取最小值为0。当系统内各事件发生概率相同时，熵取最大值\(\log_bn\)，此时系统内的不确定性最高。特别的，当\(p_i\)为0时，\(p_i \log_bp_i\)为0。
条件熵(Conditional Entropy)条件熵表示基于某条件下的信息熵。定义为：\[H(Y|X) = \sum_{i=1}^np_iH(Y|X = x_i)\]这里的\(p_i=P(X = x_i),\quad i = 1,2,3,...,n\)。\(H(Y|X = x_i)\)为\(X\)取\(x_i\)时，\(Y\)的信息熵。
信息增益(Information Gain, IG)信息增益等于信息熵减去条件熵。即：\[IG(Y, X) = H(Y) - H(Y|X)\]可以理解为在知道变量\(X\)后，\(Y\)的不确定性减少了多少。</description>
    </item>
    
    <item>
      <title>随机森林模型优化</title>
      <link>https://fanggong.pub/posts/20210426_optimise_random_forest/</link>
      <pubDate>Mon, 26 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://fanggong.pub/posts/20210426_optimise_random_forest/</guid>
      <description>森林中决策树的数量在节点进行分割的判断标准每棵树的最大深度在节点进行分割所需要的最小样本数叶子节点的最大数量寻找最佳分割时使用的特征数量使用bootstrap时的抽样数量原文地址：Random Forest: Hyperparameters and how to fine-tune them
参考链接：sklearn.ensemble.RandomForestClassifier
随机森林模型的可调参数主要包括：
森林中决策树的数量在节点进行分割的判断标准每棵树的最大深度在节点进行分割所需要的最小样本数叶子节点的最大数量寻找最佳分割时使用的特征数量使用bootstrap时的抽样数量森林中决策树的数量通过构建一个包含大量决策树的随机森林，可以得到相对低方差的、鲁棒性好的模型，虽然这个模型的构建可能需要花费大量的时间。这里的诀窍在于对数据进行评估：我们有多少的样本，每个样本又有多少的特征可用。
由于随机森林模型的随机性，如果我们的数据中包含大量的特征，那么当决策树过少时会出现一些具有高信息量的特征没有被使用，或者很少被使用的情况。
同样的，对于样本来说，如果数据中包含大量的样本，那么过少的决策树也会导致一些样本没有被使用的情况出现。
随机森林很少会出现过拟合，所以可以通过增加决策树的数量来减少模型的误差，虽然这样会大大增加模型的训练时间。唯一需要注意的是，不需要无脑增加决策树的数量，因为很显然随着决策树数量的增加，单位训练时间提供的误差减少的收益已经不是很高了。
结论：对森林中的决策树的数量进行调优是没有多大意义的，只需要将它设定为一个较大的且计算上可行的数字就可以了。
在节点进行分割的判断标准决策树通过计算判断每个节点上哪个特征的哪个值能最好地分割这个节点。这个判断的标准，在分类模型中会使用Gini或Entropy，而在回归模型中会使用MAE或MSE。
在回归模型中，如果我们的数据中没有包含大量的离群值的话，一般选择使用MSE，因为MSE会对离群值有更大的惩罚。
在分类模型中，Gini相对Entropy来说计算成本更低，但是很难断言Gini和Entropy哪个更好。
结论：由于不同的判断标准可能会构建完全不同的模型，而且其可选项也只有两种，所以建议两种都试一试吧。
每棵树的最大深度增加决策树的深度可以增加决策树中包含的特征的信息量。如果是在决策树模型下，这会导致过拟合，但是在随机森林模型中，由于集成的关系，我们可以加大树的深度。
这个参数应该根据特征的数量选择一个合理的数字，然后进行微调。但是在合理区间的微调对于模型的效果的影响微乎其微，所以其实我们在Grid Search的时候可以考虑不对这个参数进行调整。
结论：对每棵树的最大深度进行调优的意义不大，选择一个合理的数字即可。
在节点进行分割所需要的最小样本数在参考的原文中没有对这个参数进行太多描述，个人理解调整在节点进行分割所需要的最小样本数也只是一种调整单个决策树形态的手段而已，当这个参数很小时同样会导致单个决策树的过拟合，但是放到整个随机森林模型中时该问题也就不存在了。
结论：不需要对在节点进行分割所需要的最小样本数这个参数进行调整。
叶子节点的最大数量在随机森林模型中这个参数不是很重要，但是在决策树模型中，需要对这个参数进行调整以防止过拟合和提高模型的可解释性。
结论：不需要对叶子节点的最大数量这个参数进行调整。
寻找最佳分割时使用的特征数量这是随机森林模型调优时最重要的一个参数，最好的办法是通过Grid Search和Cross Validation得到最优参数，这里应该考虑一下几点：
使用较少的特征会降低集成的方差，但是会导致较高的单个决策树的偏差这个值应该根据我们的数据中高信息量高质量的特征数量来决定。如果数据中的特征都是非常干净高质量的，那么这个参数可以设定得相对较小。但是如果我们的数据中包含大量的噪声，那么这个参数应该设定的大一些以提高高信息高质量的特征被纳入的机会增加寻找最佳分割时使用的特征数量可以降低模型的偏差，因为好的特征被使用的机会大大增加了。同时，这也会导致模型的方差增大，当然，模型的训练时间也会大大增加考虑到以上几点，在使用Grid Search对该参数进行调优时，可以尝试一下几个值：
None：使用全部的特征sqrt：使用全部特征的数量开根号，即如果有25个特征，那么在寻找最佳分割时使用随机的5个特征0.</description>
    </item>
    
    <item>
      <title>Make Data Science easier</title>
      <link>https://fanggong.pub/tools/</link>
      <pubDate>Wed, 21 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://fanggong.pub/tools/</guid>
      <description>flipdownWidgetsflipdownWidgets，已上传至CRAN，通过该包我们可以在Shiny或Rmarkdown中创建一个倒计时时钟。
View Code
{&#34;x&#34;:{&#34;to&#34;:1781107200,&#34;theme&#34;:&#34;dark&#34;,&#34;headings&#34;:[&#34;天&#34;,&#34;时&#34;,&#34;分&#34;,&#34;秒&#34;]},&#34;evals&#34;:[],&#34;jsHooks&#34;:[]}</description>
    </item>
    
    <item>
      <title>WOE，IV和PSI</title>
      <link>https://fanggong.pub/posts/20210418_concepts_about_feature_selection/</link>
      <pubDate>Sun, 18 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://fanggong.pub/posts/20210418_concepts_about_feature_selection/</guid>
      <description>WOE(Weight of Evidence)和IV(Information Value)群体稳定性指标(Population Stability Index, PSI)这三个概念对我来说并不经常用到，但是每次用到的时候具体细节总是记串了，所以特别记下来。
WOE(Weight of Evidence)和IV(Information Value)WOE为“当前分组下正样本占所有正样本比例”与“当前分组下负样本占所有负样本比例”的对数差，即对包含\(\{ x_1, x_2, ..., x_n \}\)\(n\)个类别的变量\(X\)，有：\[p_{i1} = {N(Y = 1|X = x_i) \over N(Y = 1)}; \quad p_{i0} = {N(Y = 0|X = x_i) \over N(Y = 0)}\]\[WOE(x_i) = \ln { p_{i1} \over p_{i0} } \]
可以看出：
当前分组下正负样本比例与总的正负样本比例相同时，WOE的值为0当前分组下正样本比例高于总的正样本比例时，WOE值为正当前分组下正样本比例低于总的正样本比例时，WOE值为负IV为WOE的加权和，其计算方式为：
\[IV = \sum_i(p_{i1} - p_{i0})*WOE(x_i)\]</description>
    </item>
    
    <item>
      <title>git配置及操作</title>
      <link>https://fanggong.pub/posts/20210408_git/</link>
      <pubDate>Thu, 08 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://fanggong.pub/posts/20210408_git/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ggplot2：Labels</title>
      <link>https://fanggong.pub/posts/20210330_ggplot2_labels/</link>
      <pubDate>Tue, 30 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://fanggong.pub/posts/20210330_ggplot2_labels/</guid>
      <description>labs()：添加各种主副标题annotate()：添加注释labs()：添加各种主副标题ggplot(tibble(long = rnorm(100), lat = rnorm(100))) + geom_point(aes(x = long, y = lat)) +labs(x = &amp;quot;This is x-axis label&amp;quot;, y = &amp;quot;This is y-axis label&amp;quot;,title = &amp;quot;This is the title&amp;quot;,subtitle = &amp;quot;This is the subtitle&amp;quot;,caption = &amp;quot;This is the caption&amp;quot;,tag = &amp;quot;This is tag&amp;quot;)annotate()：添加注释ggplot(tibble(long = rnorm(100), lat = rnorm(100))) + geom_point(aes(x = long, y = lat)) +annotate(geom = &amp;quot;text&amp;quot;, x = 0, y = 0, label = &amp;quot;This is the annotation&amp;quot;, color = &amp;quot;blue&amp;quot;)</description>
    </item>
    
    <item>
      <title>ggplot2：Faceting</title>
      <link>https://fanggong.pub/posts/20210329_ggplot2_faceting/</link>
      <pubDate>Mon, 29 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://fanggong.pub/posts/20210329_ggplot2_faceting/</guid>
      <description>facet_grid()facet_wrap()分面函数&amp;lt;FACET_FUNCTION&amp;gt;提供了两种分面方式，第一种是网格式的分面facet_grid()，另一种facet_wrap()可以理解为将多个图按从左至右从上至下的顺序放入设计好的网格中。
facet_grid()ggplot(mpg, aes(cty, hwy)) + geom_point() + facet_grid(rows = vars(year), cols = vars(fl))facet_wrap()ggplot(mpg, aes(cty, hwy)) + facet_wrap(vars(fl), nrow = 3)</description>
    </item>
    
    <item>
      <title>ggplot2：Themes</title>
      <link>https://fanggong.pub/posts/20210327_ggplot2_themes/</link>
      <pubDate>Sat, 27 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://fanggong.pub/posts/20210327_ggplot2_themes/</guid>
      <description>完整主题直接修改当前主题主题函数&amp;lt;THEME_FUNCTION&amp;gt;包括ggplot2中自带的一些完整主题，以及对当前主题进行直接修改的函数。
完整主题theme_bw()ggplot(mpg) + geom_point(aes(x = class, y = hwy, color = trans)) +theme_bw()theme_gray()ggplot(mpg) + geom_point(aes(x = class, y = hwy, color = trans)) +theme_gray()theme_dark()ggplot(mpg) + geom_point(aes(x = class, y = hwy, color = trans)) +theme_dark()theme_classic()ggplot(mpg) + geom_point(aes(x = class, y = hwy, color = trans)) +theme_classic()theme_light()ggplot(mpg) + geom_point(aes(x = class, y = hwy, color = trans)) +theme_light()theme_linedraw()ggplot(mpg) + geom_point(aes(x = class, y = hwy, color = trans)) +theme_linedraw()theme_minimal()ggplot(mpg) + geom_point(aes(x = class, y = hwy, color = trans)) +theme_minimal()theme_void()ggplot(mpg) + geom_point(aes(x = class, y = hwy, color = trans)) +theme_void()直接修改当前主题</description>
    </item>
    
    <item>
      <title>ggplot2：Position</title>
      <link>https://fanggong.pub/posts/20210326_ggplot2_position/</link>
      <pubDate>Fri, 26 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://fanggong.pub/posts/20210326_ggplot2_position/</guid>
      <description>position = &#34;dodge&#34;：并排摆放position = &#34;fill&#34;：填充摆放position = &#34;jitter&#34;：抖动点position = &#34;stack&#34;：堆栈摆放position = &#34;jitterdodge&#34;：不是很明白实际意义&amp;lt;POSITION_FUNCTION&amp;gt;函数作为&amp;lt;STAT_FUNCTION&amp;gt;和&amp;lt;GEOM_FUNCTION&amp;gt;函数的参数使用。
position = &#34;dodge&#34;：并排摆放ggplot(mpg, aes(fl, fill = drv)) + geom_bar(position = position_dodge()) + scale_fill_brewer(palette = 1)position = &#34;fill&#34;：填充摆放ggplot(mpg, aes(fl, fill = drv)) + geom_bar(position = position_fill()) + scale_fill_brewer(palette = 1)position = &#34;jitter&#34;：抖动点ggplot(mpg, aes(cty, hwy)) + geom_point(position = position_jitter(), size = 1, alpha = 0.</description>
    </item>
    
    <item>
      <title>ggplot2：Coordinate</title>
      <link>https://fanggong.pub/posts/20210325_ggplot2_coordinate/</link>
      <pubDate>Thu, 25 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://fanggong.pub/posts/20210325_ggplot2_coordinate/</guid>
      <description>coord_cartesian()：更改笛卡尔坐标系的显示范围coord_fixed()：更改x轴和y轴的坐标比例coord_flip()：翻转坐标轴coord_polar()：将笛卡尔坐标转换成极坐标coord_trans()：进行坐标变换坐标轴函数&amp;lt;COORDINATE_FUNCTION&amp;gt;很少，个人觉得使用思路也相当清晰。
coord_cartesian()：更改笛卡尔坐标系的显示范围coord_cartesian()的作用是显示图的某一部分，并不会减少使用的数据xlim，ylim：控制x轴和y轴的范围ggplot(tibble(lat = rnorm(100), long = rnorm(100))) + geom_point(aes(x = lat, y = long)) +coord_cartesian(xlim = c(0, 5))coord_fixed()：更改x轴和y轴的坐标比例ratio：同样的数值在坐标轴上的长度y轴是x轴的ratio倍xlim，ylim：控制x轴和y轴的范围ggplot(tibble(long = 1:10, lat = 1:10*2)) +geom_point(aes(x = long, y = lat)) +coord_fixed(ratio = 1/2)coord_flip()：翻转坐标轴xlim，ylim：控制x轴和y轴的范围ggplot(tibble(letter = sample(LETTERS[1:10], 200, replace = TRUE))) +geom_bar(aes(x = letter)) +coord_flip()coord_polar()：将笛卡尔坐标转换成极坐标theta：选择哪个轴变为极坐标的thetastart：弧度，一圆周为\(2\pi\)弧度direction：1为顺时针，-1为逆时针可以通过这个函数完成很多骚操作ggplot(tibble(letter = sample(LETTERS[1:10], 200, replace = TRUE))) +geom_bar(aes(x = letter)) +coord_polar(theta = &amp;quot;x&amp;quot;, start = pi, direction = -1)coord_trans()：进行坐标变换xlim，ylim：控制x轴和y轴的范围文档中说coord_trans()函数不同于标度变换，但是用起来感觉就是一个东西ggplot(data.</description>
    </item>
    
    <item>
      <title>ggplot2：Scales</title>
      <link>https://fanggong.pub/posts/20210324_ggplot2_scales/</link>
      <pubDate>Wed, 24 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://fanggong.pub/posts/20210324_ggplot2_scales/</guid>
      <description>对连续型数据的坐标轴进行修改对离散型数据的坐标轴进行修改对时间序列数据的坐标轴进行修改TODO标度函数&amp;lt;SCALE_FUNCTION&amp;gt;应该是最麻烦的部分了，可以放进aes()函数中的元素都可以通过标度函数进行调整修改，只是所有的调整和修改改变的都是图形展示出来的样子，其背后的数据并没有做出任何改变。
对连续型数据的坐标轴进行修改相关函数包括scale_x_continuous()和scale_y_continuous()
name：坐标轴名称breaks：坐标轴主要刻度线，可以为一个向量，也可以是一个函数，函数将limits作为输入，输出一个向量作为breaks，需要注意如果使用函数输出结果貌似会受到expand参数的影响，具体影响不明minor_breaks：坐标轴次要刻度线，具体同breakslabels：坐标轴各个break点的labels，可以为一个向量，也可以是一个函数，函数将breaks作为输入，输出一个向量作为labelslimits：坐标轴范围，可以是一个长度为2的向量，也可以是一个函数，当前默认的的limits作为输入，输出新的limitsexpand：对当前的坐标轴进行一定程度扩充，用expansion()对其进行赋值mult：上下（左右）各增加当前limits的mult倍add：上下（左右）各增加add长度的坐标轴trans：直接对坐标轴进行变换，有“asn”, “atanh”, “boxcox”, “date”, “exp”, “hms”, “identity”, “log”, “log10”, “log1p”, “log2”, “logit”, “modulus”, “probability”, “probit”, “pseudo_log”, “reciprocal”, “reverse”, “sqrt” 和 “time”position：坐标轴位置，“left”，“right”，“bottom”或“right”sec.axis：增加副坐标轴，用sec.axis()对其进行赋值trans：一个对主坐标进行变换的公式name：名称breaks：主要刻度线labels：标签scale_*_log10()，scale_*_reverse()，scale_x_sqrt()提供了三种常见变换的简写通过调整数据和sec.axis可以实现双坐标轴dat &amp;lt;- tibble(Month = c(1:12), Sales = sample(1:12),CumSales = cumsum(Sales))ggplot(dat, aes(Month, Sales)) +geom_col(fill = &amp;quot;blue&amp;quot;, alpha = 0.</description>
    </item>
    
    <item>
      <title>ggplot2：Stat和Geom</title>
      <link>https://fanggong.pub/posts/20210323_ggplot2_stat_geom/</link>
      <pubDate>Tue, 23 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://fanggong.pub/posts/20210323_ggplot2_stat_geom/</guid>
      <description>对连续变量x的各区间的样本数量进行统计作图对离散变量x的各类别数量进行统计作图计算连续变量x的密度曲线并作图对区域中点的数量进行统计作图对x，y作分位数回归并作图计算并绘制x，y的拟合曲线在离散变量x的各类别上对连续变量y进行统计作图计算连续变量y的密度曲线并作图对每个点上点的数量进行统计作图计算并绘制等高线在x上对y进行summary并作图在x和y上对z进行summary并作图通过x和函数fun()计算y=fun(x)并绘制曲线计算并绘制x的经验累计分布函数计算并绘制Q-Q图二维核密度估计并作图绘制空的坐标系绘制带箭头曲线/直线绘制折线绘制多边形绘制长方形绘制区域绘制直线添加标签/文本绘制偏离原位置的点绘制散点图在图的四周绘制点的一维投影绘制区间绘制地图绘制点阵图不明白作用的函数以下是一些个人看法。
ggplot2中以geom开头的函数可以理解为作图函数，以stat开头的函数可以理解为统计变换函数。在大部分的情况下，作图函数和统计变换函数都是成对出现的，也就是说在geom函数中会有一个stat参数，而stat函数中也会有一个geom参数，从而可以通过geom或stat函数一次性达到对数据进行统计变换并作图的目的。这也是我在最初很迷这个包的原因，因为在一些很奇葩的搭配下可能会出现一些很有趣的图形，虽然图形并不一定有意义，但是思考这个图形背后形成的过程是一件很有意思的事情。
对连续变量x的各区间的样本数量进行统计作图aes()必须参数：x，y(count, density, ncount, ndensity)binwidth：每一个柱的宽度bins：柱的数量center、boundary：若center设为“t”，则有一根柱以“t”为中线；若boundary设为“t”，则有一根柱以“t”为边线breaks：直接设定每一根柱的边线位置，该参数会覆盖以上所有参数closed：若为“right”，处于交界处的值属于右边的柱子；若为“left”，处于交界处的值属于左边的柱子pad：是否在图的左右两侧加空白，若为TRUE，最后呈现的图从高度为0的柱开始到高度为0的柱结束x应该是连续的，离散的x使用stat_count()stat_bin()ggplot(mpg, aes(hwy)) + stat_bin(aes(y = ..density..), binwidth = 1, boundary = 0, pad = TRUE)geom_freqpoly()ggplot(mpg, aes(hwy)) + geom_freqpoly(binwidth = 1)geom_histogram()ggplot(mpg, aes(hwy)) + geom_histogram(binwidth = 1, boundary = 0.</description>
    </item>
    
    <item>
      <title>ggplot2：Basics</title>
      <link>https://fanggong.pub/posts/20210322_ggplot2_basics/</link>
      <pubDate>Mon, 22 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://fanggong.pub/posts/20210322_ggplot2_basics/</guid>
      <description>这份笔记实际作于好几年前，那时候刚开始接触R语言作图，觉得base R的作图系统实在过于繁琐而且感觉缺少语法上的一致性。接触ggplot2后完全沉迷于它的简单与一致性，因为ggplot2没有对应的中文文档，于是学习过程中笔记记得极其详尽，有些地方甚至到了参数的细节。
但是现在再回头看，最近两年已经很少用这个包了，主要还是由于在做研究生毕业设计的时候需要对图进行一些细微处的调整，而ggplot2由于已经自成一个世界，这种微调操作就变得相当难搞（最近在学习d3，感觉base R作图系统和ggplot2的区别有点类似于d3和echarts）。还有另一个放弃ggplot2的原因就是，它的主题已经越来越不在我的审美上了…
一张图包括最基础的ggplot()，统计变换和作图函数&amp;lt;GEOM_FUNCTION&amp;gt;，坐标轴函数&amp;lt;COORDINATE_FUNCTION&amp;gt;，分面函数&amp;lt;FACET_FUNCTION&amp;gt;，标度函数&amp;lt;SCALE_FUNCTION&amp;gt;以及主题函数&amp;lt;THEME_FUNCTION&amp;gt;
# NOT RUNggplot(data = &amp;lt;DATA&amp;gt;) +&amp;lt;GEOM_FUNCTION&amp;gt;(mapping = aes(&amp;lt;MAPPING&amp;gt;), stat = &amp;lt;STAT&amp;gt;,position = &amp;lt;POSITION&amp;gt;) +&amp;lt;COORDINATE_FUNCTION&amp;gt; +&amp;lt;FACET_FUNCTION&amp;gt; +&amp;lt;SCALE_FUNCTION&amp;gt; +&amp;lt;THEME_FUNCTION&amp;gt;last_plot()返回最后一张图
# NOT RUNlast_plot()ggsave()保存图像
# NOT RUNggsave(&amp;quot;plot.png&amp;quot;, width = 5, height = 5)</description>
    </item>
    
    <item>
      <title>关于指数族的定义</title>
      <link>https://fanggong.pub/posts/20210322_exponential_family/</link>
      <pubDate>Mon, 22 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://fanggong.pub/posts/20210322_exponential_family/</guid>
      <description>指数分布族伯努利分布的指数族形式正态分布的指数族形式分类分布的指数族形式指数分布族的概念主要应用于广义线性模型（GLM）。
指数分布族指数分布族（exponential family）的分布可以写成如下形式：
\[p(x|\eta) = h(x) g(\eta) \exp \left\{\eta^Tu(x)\right\}\]
\(\boldsymbol {\eta}\)为自然参数，是决定分布的具体参数\(\boldsymbol {u(x)}\)称作充分统计量，通常有\(\boldsymbol {u(x) = x}\)\(\boldsymbol {g(\eta)}\)称作分布正规化系数，为确保概率和为1伯努利分布的指数族形式伯努利分布的一般形式可以写为：
\[p(x|\mu) = \mu^x (1-\mu)^{1-x}\]这里为了与指数族的参数进行对应写成了这个形式，平常我们在书本中看到的最多的形式是：
\[f(x) =\begin{cases} p, &amp;amp; if &amp;amp; x = 1 \\1-p, &amp;amp; if &amp;amp; x = 0\end{cases}\]很明显是一样的。
伯努利分布可以转换成指数族的标准形式：
\[\begin{aligned}p(x|\mu) &amp;amp; = \exp \left\{ \ln {\mu^x (1-\mu)^{1-x}} \right\} \\&amp;amp; = \exp \left\{ x \ln\mu + (1-x) \ln{(1-\mu)}\right\} \\&amp;amp; = \exp \left\{ x \ln\mu - x \ln{(1-\mu)} + \ln{(1-\mu)}\right\} \\&amp;amp; = \exp \left\{ x \ln{\mu \over {1-\mu}} + \ln{(1-\mu)} \right\} \\&amp;amp; = (1-\mu) \exp \left\{ x \ln{\mu \over {1-\mu}} \right\} \end{aligned}\]于是有</description>
    </item>
    
    <item>
      <title>R语言的字符串处理</title>
      <link>https://fanggong.pub/posts/20210319_stringr/</link>
      <pubDate>Fri, 19 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://fanggong.pub/posts/20210319_stringr/</guid>
      <description>对单个字符串进行操作对空格进行操作locale sensitivepattern匹配base R与stringr的性能比较相关包：stringr
根据Introduction to stringr，该包主要包含四种类型的函数：
对字符串进行操作对空格的增加、删除或其他操作locale sensitive：可以理解为针对不同语言输出会不一样的函数pattern匹配函数：支持四种不同的匹配模式，最常用的还是正则表达式对应地，base R中也有相对应的函数达到同样的效果。在各种环境下测试，发现base R中字符串操作函数的性能在数据较大情况下普遍不如stringr。
对单个字符串进行操作此类函数对字符串进行操作，由于每个函数都已被向量化，故可以直接以字符串向量为参数
str_length()返回字符串长度
str_length(c(&amp;quot;fang&amp;quot;, &amp;quot;方&amp;quot;, NA_character_))## [1] 4 1 NAbase R中使用nchar()函数
nchar(c(&amp;quot;fang&amp;quot;, &amp;quot;方&amp;quot;, NA_character_))## [1] 4 1 NAstr_sub()返回和替换字符串子串
string &amp;lt;- c(&amp;quot;fang yongchao&amp;quot;, &amp;quot;stringr&amp;quot;)str_sub(string, start = 1, end = 4)## [1] &amp;quot;fang&amp;quot; &amp;quot;stri&amp;quot;str_sub(string, start = 1, end = 4) &amp;lt;- &amp;quot;?</description>
    </item>
    
    <item>
      <title>用R绘制流程图</title>
      <link>https://fanggong.pub/posts/20210310_diagram/</link>
      <pubDate>Wed, 10 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://fanggong.pub/posts/20210310_diagram/</guid>
      <description>创建空画板规划坐标插入BOX插入ARROW相关包：diagram
原理相当简单，创建一个空的画板，规划坐标，然后在上面插入BOX和ARROW即可。由于是在base R的体系中进行作图，所以有很高的自由度。
创建空画板该函数中有一个asp参数。个人习惯，至少在绘制流程图的时候，将它设为1，这样可以保证在设定BOX的长宽时得到的是一个稳定的图形。
openplotmat(asp = 1)规划坐标elpos &amp;lt;- coordinates(pos = c(1, 2, 3, 4), hor = FALSE)上面的代码将画板划分成了如下形式
插入BOXdiagram包共提供了九种BOX
par(mar = c(0, 0, 0, 0), family = &amp;quot;HannotateSC-W5&amp;quot;)openplotmat(asp = 1)box(col = &amp;quot;#dcdcdc&amp;quot;)elpos &amp;lt;- coordinates(pos = rep(3, 6), hor = FALSE)textdiamond(elpos[3, ], radx = 0.1, rady = 0.1, lab = &amp;quot;临&amp;quot;, cex = 2)text(elpos[6, 1], elpos[6, 2], labels = &amp;quot;textdiamond&amp;quot;)textellipse(elpos[9, ], radx = 0.</description>
    </item>
    
    <item>
      <title>About Me</title>
      <link>https://fanggong.pub/about/</link>
      <pubDate>Sat, 06 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://fanggong.pub/about/</guid>
      <description>Fang Yongchao，男，90后。
2013年本科毕业于北京理工大学数学系。
2019年研究生毕业于日本筑波大学系统情报工学系。
工作三年学三年，三年之后又三年。
在此之前从事数据分析以及相关的项目咨询及管理工作（DS方向）。
目前从事数据分析工程师工作（相对于交给别人做，还是自己做比较靠谱有意思吧）。
现阶段对数据可视化非常有兴趣。
爱好健身，剑道初段。</description>
    </item>
    
  </channel>
</rss>
