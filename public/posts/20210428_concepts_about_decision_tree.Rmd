---
title: 决策树的特征划分判断标准
author: Fang Yongchao
date: "2021-04-28"
output:
  blogdown::html_page:
    toc: yes
    toc_depth: 2
---

## 信息熵(Entropy)

--------------------------

对于系统内的多个事件$\boldsymbol{E} = \{ E_1, E_2, ..., E_n \}$，其发生的概率为$\boldsymbol{P} = \{ p_1, p_2, ..., p_n \}$，熵的定义为：
$$
\Eta(Y) = -\sum_i p_i\log_b(p_i)
$$
根据对数的底$b$的不同，熵的单位不同。

熵被认为是不确定性的度量。很显然当系统内只有一个事件且该事件必定发生时，熵取最小值为0。当系统内各事件发生概率相同时，熵取最大值$\log_bn$，此时系统内的不确定性最高。特别的，当$p_i$为0时，$p_i \log_b(p_i)$为0。

## 条件熵(Conditional Entropy)

--------------------------

条件熵表示基于某条件下的信息熵。定义为：
$$
\Eta(Y|X) = \sum_ip(x_i)\Eta(Y|X = x_i)
$$
这里的$\Eta(Y|X = x_i)$为$X$取$x_i$时，$Y$的信息熵。


## 信息增益(Information Gain, IG)

--------------------------

信息增益等于信息熵减去条件熵。即：
$$
IG(Y, X) = \Eta(Y) - \Eta(Y|X)
$$
可以理解为在知道变量$X$后，$Y$的不确定性减少了多少。

决策树的**ID3算法**中采用信息增益作为特征划分的判断标准。

## 信息增益率(Information Gain Ratio)

--------------------------

信息增益的缺点在于会偏向取值数目较多的特征，而信息增益率则可以克服该缺点：
$$
IG_{Ratio}(Y, X) = {IG(Y, X) \over \Eta(X)}
$$
即用信息增益除以特征的信息熵（在这里一般把分母部分称作特征$X$的固有值，但是计算方式和信息熵是一样的）。

决策树的**C4.5算法**中采用信息增益率作为特征划分的判断标准。

## 基尼指数(Gini)

--------------------------

基尼指数描述的是随机抽取两个样本，其类别不一致的概率，即：
$$
Gini(Y) = \sum_i p_i(1-p_i) = 1 - \sum_ip_i^2
$$
从而可以知道：
$$
Gini(Y|X) = \sum_iGini(Y|X = x_i)
$$
决策树的**CART算法**中采用基尼指数作为特征划分的判断标准。