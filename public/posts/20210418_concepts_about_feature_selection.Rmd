---
title: 特征工程中常用到的几个概念
author: Fang Yongchao
date: "2021-04-18"
output:
  blogdown::html_page:
    toc: yes
---

## 信息熵(Entropy)

--------------------------

对于系统内的多个事件$\boldsymbol{E} = \{ E_1, E_2, ..., E_n \}$，其发生的概率为$\boldsymbol{P} = \{ p_1, p_2, ..., p_n \}$，熵的定义为：
$$
\Eta(X) = -\sum_i p_i\log_b(p_i)
$$
根据对数的底$b$的不同，熵的单位不同。

熵被认为是不确定性的度量。很显然当系统内只有一个事件且该事件必定发生时，熵取最小值为0。当系统内各事件发生概率相同时，熵取最大值$\log_bn$，此时系统内的不确定性最高。特别的，当$p_i$为0时，$p_i \log_b(p_i)$为0。

## 条件熵(Conditional Entropy)

--------------------------

条件熵表示基于某条件下的信息熵。定义为：
$$
\Eta(Y|X) = \sum_ip(x_i)\Eta(Y|X = x_i)
$$
这里的$\Eta(Y|X = x_i)$为$X$取$x_i$时，$Y$的信息熵。


## 信息增益(Information Gain, IG)

--------------------------

信息增益等于信息熵减去条件熵。即：
$$
IG(Y, X) = \Eta(Y) - \Eta(Y|X)
$$
可以理解为在知道变量$X$后，$Y$的不确定性减少了多少。

## 互信息(Mutual Infomation, MI)

--------------------------

感觉完全不必纠结互信息和信息增益的区别。根据[Wiki](https://en.wikipedia.org/wiki/Mutual_information)，Mutual Information is also known as information gain。

## 证据权重(Weight of Evidence, WOE)

--------------------------

WOE为"当前分组下正样本占所有正样本比例"与"当前分组下负样本占所有负样本比例"的对数差，即对包含$\{ x_1, x_2, ..., x_n \}$$n$个类别的变量$X$，有：
$$
p_{i1} = {N(Y = 1|X = x_i) \over N(Y = 1)}; \quad 
p_{i0} = {N(Y = 0|X = x_i) \over N(Y = 0)}
$$
$$
WOE(x_i) = \ln { p_{i1} \over p_{i0} } 
$$

可以看出：

- 当前分组下正负样本比例与总的正负样本比例相同时，WOE的值为0
- 当前分组下正样本比例高于总的正样本比例时，WOE值为正
- 当前分组下正样本比例低于总的正样本比例时，WOE值为负

## 信息值(Information Value, IV)

--------------------------

IV为WOE的加权和，其计算方式为：

$$
IV = \sum_i(p_{i1} - p_{i0})*WOE(x_i)
$$

## 群体稳定性指标(Population Stability Index, PSI)

--------------------------

PSI的作用是判断变量分布的稳定性，令$A_i$和$E_i$分别为类别$i$在变量中的实际占比和预期占比，那么有：
$$
PSI = \sum_i(A_i - E_i)\ln({A_i \over E_i})
$$
很显然，PSI的值越小，变量实际和预期的分布差距越小，即变量的分布越稳定。

这里需要使用样本外的数据来计算实际占比，比如跨时间样本等。