<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>机器学习 on Connecting the dots</title>
    <link>https://fanggong.pub/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</link>
    <description>Recent content in 机器学习 on Connecting the dots</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ch</language>
    <lastBuildDate>Wed, 28 Apr 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://fanggong.pub/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>决策树的特征选择标准</title>
      <link>https://fanggong.pub/posts/20210428_concepts_about_decision_tree/</link>
      <pubDate>Wed, 28 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://fanggong.pub/posts/20210428_concepts_about_decision_tree/</guid>
      <description>信息熵(Entropy) 条件熵(Conditional Entropy) 信息增益(Information Gain, IG) 信息增益比(Information Gain Ratio) 基尼指数(Gini Index)   信息熵(Entropy) 设\(Y\)是取有限个值的离散随机变量，其概率分布为： \[ P(Y = y_i) = p_i,\quad i = 1, 2, 3, ..., n \]
则随机变量\(Y\)的熵的定义为： \[ H(Y) = -\sum_{i=1}^n p_i\log_bp_i \] 根据对数的底\(b\)的不同，熵的单位不同。当\(b\)为2时，单位为比特(bit)，当\(b\)为e时，单位为纳特(nat)。
熵被认为是不确定性的度量。很显然当系统内只有一个事件且该事件必定发生时，熵取最小值为0。当系统内各事件发生概率相同时，熵取最大值\(\log_bn\)，此时系统内的不确定性最高。特别的，当\(p_i\)为0时，\(p_i \log_bp_i\)为0。
 条件熵(Conditional Entropy) 条件熵表示基于某条件下的信息熵。定义为： \[ H(Y|X) = \sum_{i=1}^np_iH(Y|X = x_i) \] 这里的\(p_i=P(X = x_i),\quad i = 1,2,3,...,n\)。\(H(Y|X = x_i)\)为\(X\)取\(x_i\)时，\(Y\)的信息熵。
 信息增益(Information Gain, IG) 信息增益等于信息熵减去条件熵。即： \[ IG(Y, X) = H(Y) - H(Y|X) \] 可以理解为在知道变量\(X\)后，\(Y\)的不确定性减少了多少。</description>
    </item>
    
    <item>
      <title>WOE，IV和PSI</title>
      <link>https://fanggong.pub/posts/20210418_concepts_about_feature_selection/</link>
      <pubDate>Sun, 18 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://fanggong.pub/posts/20210418_concepts_about_feature_selection/</guid>
      <description>WOE(Weight of Evidence)和IV(Information Value) 群体稳定性指标(Population Stability Index, PSI)   这三个概念对我来说并不经常用到，但是每次用到的时候具体细节总是记串了，所以特别记下来。
WOE(Weight of Evidence)和IV(Information Value) WOE为“当前分组下正样本占所有正样本比例”与“当前分组下负样本占所有负样本比例”的对数差，即对包含\(\{ x_1, x_2, ..., x_n \}\)\(n\)个类别的变量\(X\)，有： \[ p_{i1} = {N(Y = 1|X = x_i) \over N(Y = 1)}; \quad p_{i0} = {N(Y = 0|X = x_i) \over N(Y = 0)} \] \[ WOE(x_i) = \ln { p_{i1} \over p_{i0} } \]
可以看出：
 当前分组下正负样本比例与总的正负样本比例相同时，WOE的值为0 当前分组下正样本比例高于总的正样本比例时，WOE值为正 当前分组下正样本比例低于总的正样本比例时，WOE值为负  IV为WOE的加权和，其计算方式为：
\[ IV = \sum_i(p_{i1} - p_{i0})*WOE(x_i) \]</description>
    </item>
    
  </channel>
</rss>
